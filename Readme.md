# Analyse et Manipulation des Données avec PySpark

Ce projet vise à réaliser une analyse et une manipulation des données à l'aide de PySpark, un framework de traitement des données distribué pour le langage de programmation Python.

## Données 
Les données utilisées dans ce projet proviennent de la ville de Chicago et sont disponibles en téléchargement à partir du lien suivant : [lien vers la donnée](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbnZJbHBCQ3JHRFRvck05RkFJZHBHU2tieHlWZ3xBQ3Jtc0ttR2dZX3E4NkI4MjdxWnFuLThlV2RKUjd4c0xtcWtEQzBaWEZnNE1KVDB4ZW5kclE0TVBfd3VBVm9SbU5nVmFrN1VEOVpVLUFKSGpPMy01QWlBMk96bzZlMXJyUU5rLTl6cERnUm5xTnNjWXp1al96TQ&q=https%3A%2F%2Fdata.cityofchicago.org%2Fapi%2Fviews%2Fijzp-q8t2%2Frows.csv%3FaccessType%3DDOWNLOAD&v=QCuQzktfQV4) . Ces données contiennent des informations sur divers aspects de la ville, notamment des données sur les crimes, les incendies, les restaurants, etc.

## Objectif
L'objectif principal de ce projet est de démontrer comment utiliser PySpark pour effectuer des opérations courantes d'analyse et de manipulation des données, telles que le filtrage, le regroupement, l'agrégation, etc. Nous utiliserons les données de la ville de Chicago comme exemple pour illustrer ces techniques.

## Contenu du Projet
Notebook PySpark: Un notebook Jupyter contenant le code Python utilisé pour l'analyse et la manipulation des données.
Script de Traitement: Un script Python autonome qui peut être utilisé pour traiter les données en vrac à l'aide de PySpark.
Rapport: Un rapport détaillant les étapes suivies, les observations faites et les conclusions tirées de l'analyse des données.
## Exécution du Code
Pour exécuter le code, assurez-vous d'avoir installé PySpark sur votre machine. Vous pouvez ensuite exécuter le notebook ou le script de traitement pour voir les résultats de l'analyse. Le tout dans COLAB